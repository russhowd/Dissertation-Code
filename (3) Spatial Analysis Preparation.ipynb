{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# specify number of rows and columns to show\n",
    "pd.set_option('display.max_rows', 25) \n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "# set default number format to 3 decimal places\n",
    "pd.options.display.float_format = '{:40,.3f}'.format\n",
    "\n",
    "# set ggplot style for plots\n",
    "plt.style.use('ggplot') \n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the cleaned dataset\n",
    "\n",
    "fulldata1 = pd.read_csv('1EveryoneActive_CLEANED.csv')\n",
    "fulldata2 = pd.read_csv('2EveryoneActive_CLEANED.csv')\n",
    "\n",
    "# Combine the two imported sets\n",
    "frames = [fulldata1, fulldata2]\n",
    "fulldata = pd.concat(frames)\n",
    "\n",
    "# Drop unused columns\n",
    "columns = ['ActivityType', 'CitySaveActiveWestminster', 'FirstVisit']\n",
    "fulldata.drop(columns, inplace=True, axis=1)\n",
    "\n",
    "# Drop duplicate MemberIDs so we are only counting each member once\n",
    "\n",
    "# First break off the '0' MembershipIDs since they are unique and we will keep them\n",
    "fulldata_0 = fulldata.loc[fulldata['MembershipID'] == 0]\n",
    "\n",
    "# Drop duplicates from the rest of the main dataset, keeping just the last instance of MembershipID\n",
    "fulldata_IDdrop = fulldata.drop_duplicates(['MembershipID'], keep='last')\n",
    "\n",
    "# Re-combine the two dataframes\n",
    "frames = [fulldata_0, fulldata_IDdrop]\n",
    "allSC = pd.concat(frames)\n",
    "\n",
    "# Drop all unknown (XXXX) postcodes for spatial analysis work\n",
    "SC_allpost = allSC.loc[allSC['Postcode'] != 'XXXX']\n",
    "\n",
    "# SPLIT THE DATA BY SPORTSCENTRE\n",
    "porch = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Porchester Hall']\n",
    "qm = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Queen Mother SC']\n",
    "marsh = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Marshall Street LC']\n",
    "sey = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Seymour LC']\n",
    "jub = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Jubilee SC']\n",
    "lv = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Little Venice SC']\n",
    "mob = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Moberly SC']\n",
    "pad = SC_allpost.loc[SC_allpost['SportsCentre'] == 'Paddington Rec Ground']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counts for each Postcode\n",
    "post_group = SC_allpost.groupby(['Postcode']).count().reset_index()\n",
    "\n",
    "# Create new column of the count per Postcode\n",
    "post_group['PostCount'] = post_group[['MembershipID']]\n",
    "post_group = post_group[['Postcode','PostCount']]\n",
    "\n",
    "# Truncate the Postcodes by removing the space in-between them\n",
    "post_group['Postcode'] = post_group['Postcode'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALCULATE THE GEODEMOGRAPHIC OF EACH OA BY AGGREGATING UP\n",
    "\n",
    "# Get the OA Acorn geodem based on which postcode geodem had the highest user count\n",
    "\n",
    "# Import postcode dataset with OA assigned\n",
    "pdata = pd.read_csv('Westminster_Postcodes w OA.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the sums of each postcode by OA.\n",
    "category_sum = pdata.groupby(['OA11CD','Category', 'CategoryTy', 'CategoryGr'],as_index=False).agg({'PostCount': 'sum'})\n",
    "\n",
    "# Find the category with the highest count by OA \n",
    "high_cat = category_sum.groupby(['OA11CD'])['PostCount'].transform(max) == category_sum['PostCount']\n",
    "high_cat = category_sum[high_cat]\n",
    "\n",
    "# Drop the summed amount from the dataframe\n",
    "high_cat = high_cat.drop(['PostCount'], axis=1)\n",
    "\n",
    "# Rename the column name for this category the column header\n",
    "high_cat = high_cat.rename(index=str, columns={\"CategoryTy\": \"CategoryType\", 'CategoryGr': 'CategoryGroup'})\n",
    "\n",
    "#Export this dataframe of Acorn category of SC users aggregated by OA\n",
    "\n",
    "#high_cat.to_csv('OA_Acorn_SC users.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but use all Acorn data (not combined Acorn + SC data as above)\n",
    "\n",
    "pdata2 = pd.read_csv('Acorn geo w OA.csv')\n",
    "\n",
    "# Create a dataframe of the categories we want. \n",
    "pdata2_dropped = pdata2[['CategoryTy','CategoryGr', 'OA11CD', 'Category']]\n",
    "\n",
    "# The lambda and mode returns either mode if the Category/Category Type/Category Group has multiple modes. Tells us the majority category of each OA\n",
    "pdata2_cut1 = pdata2_dropped.groupby(['OA11CD'])['Category'].agg(lambda x: pd.Series.mode(x)[0]).to_frame()\n",
    "\n",
    "pdata2_cut2 = pdata2_dropped.groupby(['OA11CD'])['CategoryTy'].agg(lambda x: pd.Series.mode(x)[0]).to_frame()\n",
    "\n",
    "pdata2_cut3 = pdata2_dropped.groupby(['OA11CD'])['CategoryGr'].agg(lambda x: pd.Series.mode(x)[0]).to_frame()\n",
    "\n",
    "# Combine the three dataframes into the single dataframe we'll continue to use. \n",
    "pdata_all = pdata2_cut1.merge(pdata2_cut2, how = 'inner', on = 'OA11CD')\n",
    "pdata_all = pdata_all.merge(pdata2_cut3, how = 'inner', on = 'OA11CD')\n",
    "\n",
    "pdata_all = pdata_all.rename(index=str, columns={\"CategoryTy\": \"CategoryType\", 'CategoryGr': 'CategoryGroup'})\n",
    "pdata_all = pdata_all.reset_index()\n",
    "\n",
    "# Export this dataframe of Acorn category users aggregated by OA\n",
    "\n",
    "#pdata_all.to_csv('OA_Acorn.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIDY DATA FOR SPATIAL INTERACTION MODEL\n",
    "\n",
    "# Get counts per postcode and sportscentre. \n",
    "post_group2 = SC_allpost.groupby(['Postcode', 'SportsCentre']).count().reset_index()\n",
    "post_group2.sort_values(by=['Postcode'])\n",
    "\n",
    "# Create new column of the count per Postcode\n",
    "post_group2['PostCount'] = post_group2[['MembershipID']]\n",
    "post_group2 = post_group2[['Postcode','SportsCentre','PostCount']]\n",
    "\n",
    "# Truncate the Postcodes by removing the space in-between them\n",
    "post_group2['Postcode'] = post_group2['Postcode'].str.replace(' ', '')\n",
    "\n",
    "# Append the ACORN categories and OA code using Postcode attribute\n",
    "# Rename OA and ACORN dataframe column name in order to merge\n",
    "pdata = pdata.rename({'postcode':'Postcode'}, axis='columns')\n",
    "\n",
    "# User inner merge to drop all non-Westminster postcodes. It only matches ones that we have demographics for\n",
    "post_merge2 = pd.merge(post_group2, pdata, on='Postcode', how='inner')\n",
    "\n",
    "# Rename count name to Users\n",
    "post_merge2 = post_merge2.rename({'PostCount_x':'Users'}, axis='columns')\n",
    "\n",
    "# Keep only the columns we want\n",
    "post_merge2 = post_merge2[['Postcode', 'OA11CD','SportsCentre','Users']]\n",
    "\n",
    "# Gets the user sums by each OA and Sports Centre\n",
    "user_sum = post_merge2.groupby(['OA11CD','SportsCentre'],as_index=False).agg({'Users': 'sum'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import distances\n",
    "distances = pd.read_csv('OA_SC distances.csv')\n",
    "\n",
    "# Melt the distances data into a format we can use, from wide format to long format\n",
    "d_melt=pd.melt(distances, id_vars=['ID'], value_vars=['Seymour LC', 'Queen Mother SC','Paddington Rec Ground','Moberly SC','Little Venice SC','Jubilee SC','Porchester Hall','Marshall Street LC'])\n",
    "\n",
    "# Correct column names\n",
    "d_melt = d_melt.rename({'ID':'OA11CD', 'variable': 'SportsCentre', 'value': 'Distance'}, axis='columns')\n",
    "\n",
    "# Merge distance data with the above sum data. \n",
    "OA_SC_Dist = user_sum.merge(d_melt, on=['OA11CD', 'SportsCentre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-attach all other OA details so that we can play with them in the SIM model\n",
    "\n",
    "#Upload the CSV file with all our variables\n",
    "SIM_var = pd.read_csv('Westminster OA Variables_SIM.csv')\n",
    "\n",
    "# Merge the variable data with the above sum data. \n",
    "OA_SC_Dist_Var = OA_SC_Dist.merge(SIM_var, on=['OA11CD'])\n",
    "\n",
    "# Export the melted, tidy data as csv\n",
    "#OA_SC_Dist.to_csv('Spatial Interaction Data.csv', index=False)\n",
    "\n",
    "# Export the melted, tidy data along with OA variables as csv\n",
    "#OA_SC_Dist_Var.to_csv('Spatial Interaction Data_v2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
